#!/usr/bin/env python3
"""
Clean / rewrite BLIP captions using the scene graph as ground truth.

Input JSON (LAION-SG style, e.g. from convert_vg_to_laion.py):
[
  {
    "name": "VG_100K/10.jpg",
    "img_id": "vg_10",
    "caption_ori": "...",          # raw BLIP caption
    "items": [...],                # objects
    "relations": [...],            # relations
    "constraints": [...],          # optional
  },
  ...
]

Output JSON:
- Same structure, but with an additional field "caption_clean" per entry.

Usage:

    export OPENAI_API_KEY=sk-...
    python clean_captions_with_sg.py \
        --input_json vg_train_heuristic_200.json \
        --output_json vg_train_clean_captions.json \
        --num_samples 100 \
        --model gpt-4o-mini
"""

import argparse
import json
import os
from pathlib import Path
from typing import Any, Dict, List

try:
    from openai import OpenAI
except ImportError:  # pragma: no cover
    OpenAI = None  # type: ignore


SYSTEM_PROMPT = """You are a caption rewriter that MUST stay grounded in the given scene graph.

You will receive:
- A RAW_CAPTION: a noisy caption generated by an image captioning model.
- A list of ALLOWED_OBJECTS: object categories that are actually present.
- A list of REGIONAL_DESCRIPTIONS: short phrases describing local regions
  of the image in terms of those objects and their relations.

Your task:
- Produce a SINGLE, global caption that:
  - Only mentions objects from ALLOWED_OBJECTS (no new object categories).
  - Is consistent with REGIONAL_DESCRIPTIONS as much as possible.
  - Is natural, fluent English, and works as a good image generation prompt.
- You may use synonyms/phrasing changes, but do NOT add new object types
  or obviously impossible content.
- You may add plausible attributes (colors, materials, etc.) that match
  the REGIONAL_DESCRIPTIONS or are generic (e.g., "a clear blue sky"),
  but avoid inventing completely unrelated scenes.

Output rules:
- Return ONLY the final cleaned caption text, no JSON, no extra commentary.
"""


def build_regional_descriptions(entry: Dict[str, Any]) -> List[str]:
    """Heuristically build regional descriptions from items + relations."""
    items = {it["item_id"]: it for it in entry.get("items", [])}
    rels = entry.get("relations", [])

    regions: List[str] = []

    def _obj_phrase(item_id: int) -> str:
        it = items[item_id]
        label = it["label"]
        attrs = it.get("attributes", []) or []
        attrs = attrs[:2]
        if attrs:
            return f"{', '.join(attrs)} {label}"
        return label

    for rel in rels:
        i1 = rel["item1"]
        i2 = rel["item2"]
        if i1 not in items or i2 not in items:
            continue
        subj = _obj_phrase(i1)
        obj = _obj_phrase(i2)
        pred = rel["relation"]

        if pred in {"on", "under", "behind", "in front of", "next to", "near", "in"}:
            text = f"{subj} {pred} {obj}"
        else:
            text = f"{subj} {pred} {obj}"
        regions.append(text)

    seen = set()
    uniq_regions = []
    for r in regions:
        if r not in seen:
            seen.add(r)
            uniq_regions.append(r)
    return uniq_regions


def build_user_prompt(entry: Dict[str, Any]) -> str:
    raw_caption = entry.get("caption_ori", "")
    items = entry.get("items", [])

    allowed_objects = sorted({it["label"] for it in items})
    regions = build_regional_descriptions(entry)

    parts: List[str] = []
    parts.append("RAW_CAPTION:")
    parts.append(raw_caption.strip())
    parts.append("\nALLOWED_OBJECTS (only these object categories may be mentioned):")
    parts.append(", ".join(allowed_objects))

    if regions:
        parts.append("\nREGIONAL_DESCRIPTIONS (hints, may be partial):")
        for r in regions[:12]:
            parts.append(f"- {r}")
    else:
        parts.append("\nREGIONAL_DESCRIPTIONS: (none available) ")

    parts.append(
        "\nNow rewrite the RAW_CAPTION into a single, globally consistent caption "
        "that obeys the constraints above."
    )
    return "\n".join(parts)


def call_llm(prompt: str, model: str, temperature: float) -> str:
    if OpenAI is None:
        raise RuntimeError(
            "openai package not installed. Please `pip install openai` and "
            "set OPENAI_API_KEY."
        )
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY environment variable is not set.")

    client = OpenAI(api_key=api_key)
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
    )
    text = resp.choices[0].message.content or ""
    return text.strip()


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Clean BLIP captions using scene graphs.")
    p.add_argument("--input_json", type=Path, required=True,
                   help="Input LAION-style JSON with caption_ori/items/relations.")
    p.add_argument("--output_json", type=Path, required=True,
                   help="Output JSON with added caption_clean field.")
    p.add_argument("--num_samples", type=int, default=None,
                   help="Limit number of entries to process (for debugging).")
    p.add_argument("--model", type=str, default="gpt-4o-mini",
                   help="OpenAI model name.")
    p.add_argument("--temperature", type=float, default=0.3,
                   help="Sampling temperature.")
    return p.parse_args()


def main() -> None:
    args = parse_args()

    data = json.loads(args.input_json.read_text())
    if args.num_samples is not None:
        data = data[: args.num_samples]

    cleaned: List[Dict[str, Any]] = []

    for i, entry in enumerate(data):
        caption = entry.get("caption_ori", "").strip()
        if not caption:
            cleaned.append(entry)
            continue

        user_prompt = build_user_prompt(entry)
        try:
            new_caption = call_llm(user_prompt, model=args.model, temperature=args.temperature)
        except Exception as e:  # pragma: no cover
            print(f"[WARN] LLM caption cleaning failed at index {i}: {e}")
            cleaned.append(entry)
            continue

        entry = dict(entry)
        entry["caption_clean"] = new_caption
        cleaned.append(entry)

        if (i + 1) % 10 == 0:
            print(f"Processed {i + 1} captions...")

    print(f"Saving {len(cleaned)} entries to {args.output_json} ...")
    args.output_json.write_text(json.dumps(cleaned, indent=2))
    print("Done.")


if __name__ == "__main__":
    main()


